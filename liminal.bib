
@MISC{Lyttle2020-nq,
  title  = "vegawidget: 'Htmlwidget' for 'Vega' and {'Vega-Lite'}",
  author = "Lyttle, Ian and {Vega/Vega-Lite Developers}",
  year   =  2020,
  url    = "https://CRAN.R-project.org/package=vegawidget"
}

@UNPUBLISHED{Moon2019-ce,
  title    = "Visualizing Structure and Transitions for Biological Data
              Exploration",
  author   = "Moon, Kevin R and van Dijk, David and Wang, Zheng and Gigante,
              Scott and Burkhardt, Daniel B and Chen, William S and Yim,
              Kristina and van den Elzen, Antonia and Hirn, Matthew J and
              Coifman, Ronald R and Ivanova, Natalia B and Wolf, Guy and
              Krishnaswamy, Smita",
  abstract = "Abstract With the advent of high-throughput technologies
              measuring high-dimensional biological data, there is a pressing
              need for visualization tools that reveal the structure and
              emergent patterns of data in an intuitive form. We present PHATE,
              a visualization method that captures both local and global
              nonlinear structure in data by an information-geometric distance
              between datapoints. We perform extensive comparison between PHATE
              and other tools on a variety of artificial and biological
              datasets, and find that it consistently preserves a range of
              patterns in data including continual progressions, branches, and
              clusters. We define a manifold preservation metric DEMaP to show
              that PHATE produces quantitatively better denoised embeddings
              than existing visualization methods. We show that PHATE is able
              to gain unique insight from a newly generated scRNA-seq dataset
              of human germ layer differentiation. Here, PHATE reveals a
              dynamic picture of the main developmental branches in
              unparalleled detail, including the identification of three novel
              subpopulations. Finally, we show that PHATE is applicable to a
              wide variety of datatypes including mass cytometry, single-cell
              RNA-sequencing, Hi-C, and gut microbiome data, where it can
              generate interpretable insights into the underlying systems.",
  journal  = "bioRxiv",
  pages    = "120378",
  month    =  apr,
  year     =  2019,
  url      = "https://www.biorxiv.org/content/10.1101/120378v4",
  language = "en",
  doi      = "10.1101/120378"
}

@ARTICLE{Satyanarayan2016-yb,
  title    = "Reactive Vega: A Streaming Dataflow Architecture for Declarative
              Interactive Visualization",
  author   = "Satyanarayan, A and Russell, R and Hoffswell, J and Heer, J",
  abstract = "We present Reactive Vega, a system architecture that provides the
              first robust and comprehensive treatment of declarative visual
              and interaction design for data visualization. Starting from a
              single declarative specification, Reactive Vega constructs a
              dataflow graph in which input data, scene graph elements, and
              interaction events are all treated as first-class streaming data
              sources. To support expressive interactive visualizations that
              may involve time-varying scalar, relational, or hierarchical
              data, Reactive Vega's dataflow graph can dynamically re-write
              itself at runtime by extending or pruning branches in a
              data-driven fashion. We discuss both compile- and run-time
              optimizations applied within Reactive Vega, and share the results
              of benchmark studies that indicate superior interactive
              performance to both D3 and the original, non-reactive Vega
              system.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  22,
  number   =  1,
  pages    = "659--668",
  month    =  jan,
  year     =  2016,
  url      = "http://dx.doi.org/10.1109/TVCG.2015.2467091",
  keywords = "data flow graphs;data visualisation;formal
              specification;optimisation;Reactive Vega;streaming dataflow
              architecture;declarative interactive visualization;system
              architecture;declarative visual design;interaction design;data
              visualization;single declarative specification;dataflow
              graph;scene graph elements;interaction events;first-class
              streaming data sources;expressive interactive
              visualizations;time-varying scalar;relational data;hierarchical
              data;compile-time optimization;run-time optimization;interactive
              performance;Data visualization;Visualization;Data
              models;Encoding;Indexes;Runtime;Computer architecture;Information
              visualization;systems;toolkits;declarative
              specification;optimization;interaction;streaming data;Information
              visualization;systems;toolkits;declarative
              specification;optimization;interaction;streaming data",
  issn     = "1077-2626, 2160-9306",
  doi      = "10.1109/TVCG.2015.2467091"
}

@ARTICLE{Bostock2011-gc,
  title    = "D3: {Data-Driven} Documents",
  author   = "Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey",
  abstract = "Data-Driven Documents (D3) is a novel representation-transparent
              approach to visualization for the web. Rather than hide the
              underlying scenegraph within a toolkit-specific abstraction, D3
              enables direct inspection and manipulation of a native
              representation: the standard document object model (DOM). With
              D3, designers selectively bind input data to arbitrary document
              elements, applying dynamic transforms to both generate and modify
              content. We show how representational transparency improves
              expressiveness and better integrates with developer tools than
              prior approaches, while offering comparable notational efficiency
              and retaining powerful declarative components. Immediate
              evaluation of operators further simplifies debugging and allows
              iterative development. Additionally, we demonstrate how D3
              transforms naturally enable animation and interaction with
              dramatic performance improvements over intermediate
              representations.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  17,
  number   =  12,
  pages    = "2301--2309",
  month    =  dec,
  year     =  2011,
  url      = "http://dx.doi.org/10.1109/TVCG.2011.185",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "22034350",
  doi      = "10.1109/TVCG.2011.185"
}

@ARTICLE{Chang2017-rt,
  title   = "Shiny: web application framework for {R}",
  author  = "Chang, Winston and Cheng, Joe and Allaire, J and Xie, Yihui and
             McPherson, Jonathan and {Others}",
  journal = "R package version",
  volume  =  1,
  number  =  5,
  year    =  2017
}

@ARTICLE{Linderman2019-dq,
  title     = "Clustering with {t-SNE}, Provably",
  author    = "Linderman, George C and Steinerberger, Stefan",
  abstract  = "t-distributed stochastic neighborhood embedding (t-SNE), a
               clustering and visualization method proposed by van der Maaten
               and Hinton in 2008, has rapidly become a standard tool in a
               number of natural sciences. Despite its overwhelming success,
               there is a distinct lack of mathematical foundations, and the
               inner workings of the algorithm are not well understood. The
               purpose of this paper is to prove that t-SNE is able to recover
               well-separated clusters; more precisely, we prove that t-SNE in
               the ?early exaggeration? phase, an optimization technique
               proposed by van der Maaten and Hinton [J. Mach. Learn. Res., 9
               (2008), pp. 2579--2605] and van der Maaten [J. Mach. Learn.
               Res., 15 (2014), pp. 3221--3245], can be rigorously analyzed. As
               a byproduct, the proof suggests novel ways for setting the
               exaggeration parameter $\alpha$ and step size $h$. Numerical
               examples illustrate the effectiveness of these rules: in
               particular, the quality of embedding of topological structures
               (e.g., the swiss roll) improves. We also discuss a connection to
               spectral clustering methods.",
  journal   = "SIAM Journal on Mathematics of Data Science",
  publisher = "Society for Industrial and Applied Mathematics",
  volume    =  1,
  number    =  2,
  pages     = "313--332",
  month     =  jan,
  year      =  2019,
  url       = "https://doi.org/10.1137/18M1216134",
  doi       = "10.1137/18M1216134"
}

@ARTICLE{Kobak2019-lm,
  title    = "The art of using {t-SNE} for single-cell transcriptomics",
  author   = "Kobak, Dmitry and Berens, Philipp",
  abstract = "Single-cell transcriptomics yields ever growing data sets
              containing RNA expression levels for thousands of genes from up
              to millions of cells. Common data analysis pipelines include a
              dimensionality reduction step for visualising the data in two
              dimensions, most frequently performed using t-distributed
              stochastic neighbour embedding (t-SNE). It excels at revealing
              local structure in high-dimensional data, but naive applications
              often suffer from severe shortcomings, e.g. the global structure
              of the data is not represented accurately. Here we describe how
              to circumvent such pitfalls, and develop a protocol for creating
              more faithful t-SNE visualisations. It includes PCA
              initialisation, a high learning rate, and multi-scale similarity
              kernels; for very large data sets, we additionally use
              exaggeration and downsampling-based initialisation. We use
              published single-cell RNA-seq data sets to demonstrate that this
              protocol yields superior results compared to the naive
              application of t-SNE.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "5416",
  month    =  nov,
  year     =  2019,
  url      = "http://dx.doi.org/10.1038/s41467-019-13056-x",
  language = "en",
  issn     = "2041-1723",
  pmid     = "31780648",
  doi      = "10.1038/s41467-019-13056-x",
  pmc      = "PMC6882829"
}


@INPROCEEDINGS{Brehmer2014-hk,
  title     = "Visualizing dimensionally-reduced data: Interviews with analysts
               and a characterization of task sequences",
  booktitle = "Proceedings of the Fifth Workshop on Beyond Time and Errors:
               Novel Evaluation Methods for Visualization",
  author    = "Brehmer, Matthew and Sedlmair, Michael and Ingram, Stephen and
               Munzner, Tamara",
  publisher = "dl.acm.org",
  pages     = "1--8",
  year      =  2014,
  url       = "https://dl.acm.org/doi/abs/10.1145/2669557.2669559"
}

@INPROCEEDINGS{Colange2019-ba,
  title     = "Interpreting Distortions in Dimensionality Reduction by
               Superimposing Neighbourhood Graphs",
  booktitle = "2019 {IEEE} Visualization Conference ({VIS})",
  author    = "Colange, B and Vuillon, L and Lespinats, S and Dutykh, D",
  abstract  = "To perform visual data exploration, many dimensionality
               reduction methods have been developed. These tools allow data
               analysts to represent multidimensional data in a 2D or 3D space,
               while preserving as much relevant information as possible. Yet,
               they cannot preserve all structures simultaneously and they
               induce some unavoidable distortions. Hence, many criteria have
               been introduced to evaluate a map's overall quality, mostly
               based on the preservation of neighbourhoods. Such global
               indicators are currently used to compare several maps, which
               helps to choose the most appropriate mapping method and its
               hyperparameters. However, those aggregated indicators tend to
               hide the local repartition of distortions. Thereby, they need to
               be supplemented by local evaluation to ensure correct
               interpretation of maps.In this paper, we describe a new method,
               called MING, for ``Map Interpretation using Neighbourhood
               Graphs''. It offers a graphical interpretation of pairs of map
               quality indicators, as well as local evaluation of the
               distortions. This is done by displaying on the map the nearest
               neighbours graphs computed in the data space and in the
               embedding. Shared and unshared edges exhibit reliable and
               unreliable neighbourhood information conveyed by the mapping. By
               this mean, analysts may determine whether proximity (or
               remoteness) of points on the map faithfully represents
               similarity (or dissimilarity) of original data, within the
               meaning of a chosen map quality criteria. We apply this approach
               to two pairs of widespread indicators: precision/recall and
               trustworthiness/continuity, chosen for their wide use in the
               community, which will allow an easy handling by users.",
  pages     = "211--215",
  month     =  oct,
  year      =  2019,
  url       = "http://dx.doi.org/10.1109/VISUAL.2019.8933568",
  keywords  = "Distortion;Reliability;Image color analysis;Data
               visualization;Visualization;Dimensionality
               reduction;Three-dimensional displays;Evaluation---Qualitative
               Evaluation;Non-Spatial Data and Techniques---Dimensionality
               Reduction;Visual Analysis and Knowledge Discovery---Visual
               Knowledge Discovery",
  doi       = "10.1109/VISUAL.2019.8933568"
}

@ARTICLE{Nguyen2019-yh,
  title    = "Ten quick tips for effective dimensionality reduction",
  author   = "Nguyen, Lan Huong and Holmes, Susan",
  journal  = "PLoS Comput. Biol.",
  volume   =  15,
  number   =  6,
  pages    = "e1006907",
  month    =  jun,
  year     =  2019,
  url      = "http://dx.doi.org/10.1371/journal.pcbi.1006907",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "31220072",
  doi      = "10.1371/journal.pcbi.1006907",
  pmc      = "PMC6586259"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Lewis2012-ai,
  title     = "A behavioral investigation of dimensionality reduction",
  booktitle = "Proceedings of the Annual Meeting of the Cognitive Science
               Society",
  author    = "Lewis, Joshua and Van der Maaten, Laurens and de Sa, Virginia",
  abstract  = "A cornucopia of dimensionality reduction techniques have emerged
               over the past decade, leaving data analysts with a wide variety
               of choices for reducing their data. Means of evaluating and
               comparing low-dimensional embeddings useful for visualization,
               however, are very limited. When proposing a new technique it is
               common to simply show rival embeddings side-by-side and let
               human judgment determine which embedding is superior. This study
               investigates whether such human embedding evaluations are
               reliable, ie …",
  publisher = "escholarship.org",
  volume    =  34,
  year      =  2012,
  url       = "https://escholarship.org/content/qt0ss3m55c/qt0ss3m55c.pdf"
}

@ARTICLE{Sedlmair2013-pn,
  title    = "Empirical guidance on scatterplot and dimension reduction
              technique choices",
  author   = "Sedlmair, Michael and Munzner, Tamara and Tory, Melanie",
  abstract = "To verify cluster separation in high-dimensional data, analysts
              often reduce the data with a dimension reduction (DR) technique,
              and then visualize it with 2D Scatterplots, interactive 3D
              Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of
              providing guidance between these visual encoding choices, we
              conducted an empirical data study in which two human coders
              manually inspected a broad set of 816 scatterplots derived from
              75 datasets, 4 DR techniques, and the 3 previously mentioned
              scatterplot techniques. Each coder scored all color-coded classes
              in each scatterplot in terms of their separability from other
              classes. We analyze the resulting quantitative data with a
              heatmap approach, and qualitatively discuss interesting
              scatterplot examples. Our findings reveal that 2D scatterplots
              are often 'good enough', that is, neither SPLOM nor interactive
              3D adds notably more cluster separability with the chosen DR
              technique. If 2D is not good enough, the most promising approach
              is to use an alternative DR technique in 2D. Beyond that, SPLOM
              occasionally adds additional value, and interactive 3D rarely
              helps but often hurts in terms of poorer class separation and
              usability. We summarize these results as a workflow model and
              implications for design. Our results offer guidance to analysts
              during the DR exploration process.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  19,
  number   =  12,
  pages    = "2634--2643",
  month    =  dec,
  year     =  2013,
  url      = "http://dx.doi.org/10.1109/TVCG.2013.153",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "24051830",
  doi      = "10.1109/TVCG.2013.153"
}

@PHDTHESIS{Rieck2017-kk,
  title  = "Persistent Homology in Multivariate Data Visualization",
  author = "Rieck, Bastian",
  editor = "Little, Heike and Gertz, Michael",
  year   =  2017,
  school = "Ruprecht-Karls-Universit{\"a}t Heidelberg"
}

@ARTICLE{Genovese2014-wt,
  title     = "Nonparametric ridge estimation",
  author    = "Genovese, Christopher R and Perone-Pacifico, Marco and
               Verdinelli, Isabella and Wasserman, Larry",
  abstract  = "Project Euclid - mathematics and statistics online",
  journal   = "Ann. Stat.",
  publisher = "Institute of Mathematical Statistics",
  volume    =  42,
  number    =  4,
  pages     = "1511--1545",
  month     =  aug,
  year      =  2014,
  url       = "https://projecteuclid.org/euclid.aos/1407420007",
  keywords  = "Ridges; density estimation; manifold learning",
  language  = "en",
  issn      = "0090-5364, 2168-8966",
  doi       = "10.1214/14-AOS1218"
}

@ARTICLE{Genovese2017-iq,
  title     = "Finding Singular Features",
  author    = "Genovese, Christopher and Perone-Pacifico, Marco and Verdinelli,
               Isabella and Wasserman, Larry",
  abstract  = "ABSTRACTWe present a method for finding high density,
               low-dimensional structures in noisy point clouds. These
               structures are sets with zero Lebesgue measure with respect to
               the D-dimensional ambient space and belong to a d <
               D-dimensional space. We call them ?singular features.? Hunting
               for singular features corresponds to finding unexpected or
               unknown structures hidden in point clouds belonging to RD. Our
               method outputs well-defined sets of dimensions d < D. Unlike
               spectral clustering, the method works well in the presence of
               noise. We show how to find singular features by first finding
               ridges in the estimated density, followed by a filtering step
               based on the eigenvalues of the Hessian of the density. The code
               for plotting all the figures, with the corresponding plots, and
               the data files used in the article, are in the folder
               SupplementaryDocument.zip that can be find at the
               http://www.stat.cmu.edu/larry/singular.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  26,
  number    =  3,
  pages     = "598--609",
  month     =  jul,
  year      =  2017,
  url       = "https://doi.org/10.1080/10618600.2016.1260472",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.2016.1260472"
}

@ARTICLE{Carr1987-ln,
  title     = "Scatterplot Matrix Techniques for Large {N}",
  author    = "Carr, D B and Littlefield, R J and Nicholson, W L and
               Littlefield, J S",
  abstract  = "[High-performance interaction with scatterplot matrices is a
               powerful approach to exploratory multivariate data analysis. For
               a small number of data points, real-time interaction is possible
               and overplotting is usually not a major problem. When the number
               of plotted points is large, however, display techniques that
               deal with overplotting and slow production are important. This
               article addresses these two problems. Topics include density
               representation by gray scale or by symbol area, alternatives to
               brushing, and animation sequences. We also discuss techniques
               that are generally applicable, including interactive graphical
               subset selection from any plot in a collection of scatterplots
               and comparison of scatterplot matrices.]",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.]",
  volume    =  82,
  number    =  398,
  pages     = "424--436",
  year      =  1987,
  url       = "http://www.jstor.org/stable/2289444",
  issn      = "0162-1459",
  doi       = "10.2307/2289444"
}

@INCOLLECTION{Cook2006-ay,
  title     = "Rotating Plots",
  booktitle = "Graphics of Large Datasets: Visualizing a Million",
  author    = "Cook, Dianne and Miller, Leslie",
  editor    = "Unwin, Antony and Theus, Martin and Hofmann, Heike",
  publisher = "Springer New York",
  pages     = "125--141",
  year      =  2006,
  url       = "https://doi.org/10.1007/0-387-37977-0_6",
  address   = "New York, NY",
  isbn      = "9780387379777",
  doi       = "10.1007/0-387-37977-0\_6"
}

@ARTICLE{Jarvis1973-sq,
  title    = "Clustering Using a Similarity Measure Based on Shared Near
              Neighbors",
  author   = "Jarvis, R A and Patrick, E A",
  abstract = "A nonparametric clustering technique incorporating the concept of
              similarity based on the sharing of near neighbors is presented.
              In addition to being an essentially paraliel approach, the
              computational elegance of the method is such that the scheme is
              applicable to a wide class of practical problems involving large
              sample size and high dimensionality. No attempt is made to show
              how a priori problem knowledge can be introduced into the
              procedure.",
  journal  = "IEEE Trans. Comput.",
  volume   = "C-22",
  number   =  11,
  pages    = "1025--1034",
  month    =  nov,
  year     =  1973,
  url      = "http://dx.doi.org/10.1109/T-C.1973.223640",
  keywords = "Clustering, nonparametric, pattern recognition, shared near
              neighbors, similarity measure.;Clustering, nonparametric, pattern
              recognition, shared near neighbors, similarity measure.",
  issn     = "0018-9340, 2326-3814",
  doi      = "10.1109/T-C.1973.223640"
}

@UNPUBLISHED{Ovchinnikova2019-gf,
  title    = "Exploring dimension-reduced embeddings with Sleepwalk",
  author   = "Ovchinnikova, Svetlana and Anders, Simon",
  abstract = "Abstract Dimension-reduction methods, such as t-SNE or UMAP, are
              widely used when exploring high-dimensional data describing many
              entities, e.g., RNA-Seq data for many single cells. However,
              dimension reduction is unavoidably prone to introducing
              artefacts, and we hence need means to see where a
              dimension-reduced embedding is a faithful representation of the
              local neighbourhood and where it is not.We present Sleepwalk, a
              simple but powerful tool that allows the user to interactively
              explore an embedding, using colour to depict ``true''
              similarities of all points to the cell under the mouse cursor. We
              show how this approach not only highlights distortions, but also
              reveals otherwise hidden characteristics of the data, and how
              Sleepwalk's comparative modes help integrate multi-sample data
              and understand differences between embedding and preprocessing
              methods. Sleepwalk is a versatile and intuitive tool that unlocks
              the full power of dimension reduction and will be of value not
              only in single-cell RNA-Seq but also in any other area with
              matrix-shaped big data.",
  journal  = "bioRxiv",
  pages    = "603589",
  month    =  apr,
  year     =  2019,
  url      = "https://www.biorxiv.org/content/10.1101/603589v1",
  language = "en",
  doi      = "10.1101/603589"
}

@ARTICLE{Pezzotti2017-cz,
  title    = "Approximated and User Steerable {tSNE} for Progressive Visual
              Analytics",
  author   = "Pezzotti, Nicola and Lelieveldt, Boudewijn P F and Van Der
              Maaten, Laurens and Hollt, Thomas and Eisemann, Elmar and
              Vilanova, Anna",
  abstract = "Progressive Visual Analytics aims at improving the interactivity
              in existing analytics techniques by means of visualization as
              well as interaction with intermediate results. One key method for
              data analysis is dimensionality reduction, for example, to
              produce 2D embeddings that can be visualized and analyzed
              efficiently. t-Distributed Stochastic Neighbor Embedding (tSNE)
              is a well-suited technique for the visualization of
              high-dimensional data. tSNE can create meaningful intermediate
              results but suffers from a slow initialization that constrains
              its application in Progressive Visual Analytics. We introduce a
              controllable tSNE approximation (A-tSNE), which trades off speed
              and accuracy, to enable interactive data exploration. We offer
              real-time visualization techniques, including a density-based
              solution and a Magic Lens to inspect the degree of approximation.
              With this feedback, the user can decide on local refinements and
              steer the approximation level during the analysis. We demonstrate
              our technique with several datasets, in a real-world research
              scenario and for the real-time analysis of high-dimensional
              streams to illustrate its effectiveness for interactive data
              analysis.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  23,
  number   =  7,
  pages    = "1739--1752",
  month    =  jul,
  year     =  2017,
  url      = "http://dx.doi.org/10.1109/TVCG.2016.2570755",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "28113434",
  doi      = "10.1109/TVCG.2016.2570755"
}

@ARTICLE{Linderman2019-le,
  title    = "Fast interpolation-based {t-SNE} for improved visualization of
              single-cell {RNA-seq} data",
  author   = "Linderman, George C and Rachh, Manas and Hoskins, Jeremy G and
              Steinerberger, Stefan and Kluger, Yuval",
  abstract = "t-distributed stochastic neighbor embedding (t-SNE) is widely
              used for visualizing single-cell RNA-sequencing (scRNA-seq) data,
              but it scales poorly to large datasets. We dramatically
              accelerate t-SNE, obviating the need for data downsampling, and
              hence allowing visualization of rare cell populations.
              Furthermore, we implement a heatmap-style visualization for
              scRNA-seq based on one-dimensional t-SNE for simultaneously
              visualizing the expression patterns of thousands of genes.
              Software is available at https://github.com/KlugerLab/FIt-SNE and
              https://github.com/KlugerLab/t-SNE-Heatmaps .",
  journal  = "Nat. Methods",
  volume   =  16,
  number   =  3,
  pages    = "243--245",
  month    =  mar,
  year     =  2019,
  url      = "http://dx.doi.org/10.1038/s41592-018-0308-4",
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "30742040",
  doi      = "10.1038/s41592-018-0308-4",
  pmc      = "PMC6402590"
}

@ARTICLE{Kobak2019-ir,
  title         = "Heavy-tailed kernels reveal a finer cluster structure in
                   {t-SNE} visualisations",
  author        = "Kobak, Dmitry and Linderman, George and Steinerberger,
                   Stefan and Kluger, Yuval and Berens, Philipp",
  abstract      = "T-distributed stochastic neighbour embedding (t-SNE) is a
                   widely used data visualisation technique. It differs from
                   its predecessor SNE by the low-dimensional similarity
                   kernel: the Gaussian kernel was replaced by the heavy-tailed
                   Cauchy kernel, solving the ``crowding problem'' of SNE.
                   Here, we develop an efficient implementation of t-SNE for a
                   $t$-distribution kernel with an arbitrary degree of freedom
                   $\nu$, with $\nu\to\infty$ corresponding to SNE and $\nu=1$
                   corresponding to the standard t-SNE. Using theoretical
                   analysis and toy examples, we show that $\nu<1$ can further
                   reduce the crowding problem and reveal finer cluster
                   structure that is invisible in standard t-SNE. We further
                   demonstrate the striking effect of heavier-tailed kernels on
                   large real-life data sets such as MNIST, single-cell
                   RNA-sequencing data, and the HathiTrust library. We use
                   domain knowledge to confirm that the revealed clusters are
                   meaningful. Overall, we argue that modifying the tail
                   heaviness of the t-SNE kernel can yield additional insight
                   into the cluster structure of the data.",
  month         =  feb,
  year          =  2019,
  url           = "http://arxiv.org/abs/1902.05804",
  archivePrefix = "arXiv",
  eprint        = "1902.05804",
  primaryClass  = "cs.LG",
  arxivid       = "1902.05804"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Van_Der_Maaten2014-zn,
  title     = "Accelerating {t-SNE} using tree-based algorithms",
  author    = "Van Der Maaten, L",
  abstract  = "The paper investigates the acceleration of t-SNE---an embedding
               technique that is commonly used for the visualization of
               high-dimensional data in scatter plots---using two treebased
               algorithms. In particular, the paper develops variants of the
               Barnes-Hut algorithm and of the dual-tree algorithm that
               approximate the gradient used for learning t-SNE embeddings in O
               (N log N). Our experiments show that the resulting algorithms
               substantially accelerate t-SNE, and that they make it possible
               to learn embeddings of data sets with …",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  year      =  2014,
  url       = "http://www.jmlr.org/papers/volume15/vandermaaten14a/vandermaaten14a.pdf",
  issn      = "1532-4435"
}

@ARTICLE{Wickham2011-st,
  title    = "tourr: An {R} Package for Exploring Multivariate Data with
              Projections",
  author   = "Wickham, Hadley and Cook, Dianne and Hofmann, Heike and Buja,
              Andreas",
  abstract = "This paper describes an R package which produces tours of
              multivariate data. The package includes functions for creating
              different types of tours, including grand, guided, and little
              tours, which project multivariate data (p-D) down to 1, 2, 3, or,
              more generally, d ($\leq$ p) dimensions. The projected data can
              be rendered as densities or histograms, scatterplots, anaglyphs,
              glyphs, scatterplot matrices, parallel coordinate plots, time
              series or images, and viewed using an R graphics device, passed
              to GGobi, or saved to disk. A tour path can be stored for
              visualisation or replay. With this package it is possible to
              quickly experiment with different, and new, approaches to tours
              of data. This paper contains animations that can be viewed using
              the Adobe Acrobat PDF viewer.",
  journal  = "Journal of Statistical Software, Articles",
  volume   =  40,
  number   =  2,
  pages    = "1--18",
  year     =  2011,
  url      = "https://www.jstatsoft.org/v040/i02",
  issn     = "1548-7660",
  doi      = "10.18637/jss.v040.i02"
}

@INCOLLECTION{Buja2005-hx,
  title     = "14 - Computational Methods for {High-Dimensional} Rotations in
               Data Visualization",
  booktitle = "Handbook of Statistics",
  author    = "Buja, Andreas and Cook, Dianne and Asimov, Daniel and Hurley,
               Catherine",
  editor    = "Rao, C R and Wegman, E J and Solka, J L",
  abstract  = "There exist many methods for visualizing complex relations among
               variables of a multivariate dataset. For pairs of quantitative
               variables, the method of choice is the scatterplot. For triples
               of quantitative variables, the method of choice is 3D data
               rotations. Such rotations let us perceive structure among three
               variables as shape of point scatters in virtual 3D space.
               Although not obvious, three-dimensional data rotations can be
               extended to higher dimensions. The mathematical construction of
               high-dimensional data rotations, however, is not an intuitive
               generalization. Whereas three-dimensional data rotations are
               thought of as rotations of an object in space, a proper
               framework for their high-dimensional extension is better based
               on rotations of a low-dimensional projection in high-dimensional
               space. The term ``data rotations'' is therefore a misnomer, and
               something along the lines of ``high-to-low dimensional data
               projections'' would be technically more accurate. To be useful,
               virtual rotations need to be under interactive user control, and
               they need to be animated. We therefore require projections not
               as static pictures but as movies under user control. Movies,
               however, are mathematically speaking one-parameter families of
               pictures. This article is therefore about one-parameter families
               of low-dimensional projections in high-dimensional data spaces.
               We describe several algorithms for dynamic projections, all
               based on the idea of smoothly interpolating a discrete sequence
               of projections. The algorithms lend themselves to the
               implementation of interactive visual exploration tools of
               high-dimensional data, such as so-called grand tours, guided
               tours and manual tours.",
  publisher = "Elsevier",
  volume    =  24,
  pages     = "391--413",
  month     =  jan,
  year      =  2005,
  url       = "http://www.sciencedirect.com/science/article/pii/S0169716104240147",
  doi       = "10.1016/S0169-7161(04)24014-7"
}

@ARTICLE{Faust2018-dm,
  title         = "{DimReader}: Axis lines that explain non-linear projections",
  author        = "Faust, Rebecca and Glickenstein, David and Scheidegger,
                   Carlos",
  abstract      = "Non-linear dimensionality reduction (NDR) methods such as
                   LLE and t-SNE are popular with visualization researchers and
                   experienced data analysts, but present serious problems of
                   interpretation. In this paper, we present DimReader, a
                   technique that recovers readable axes from such techniques.
                   DimReader is based on analyzing infinitesimal perturbations
                   of the dataset with respect to variables of interest. The
                   perturbations define exactly how we want to change each
                   point in the original dataset and we measure the effect that
                   these changes have on the projection. The recovered axes are
                   in direct analogy with the axis lines (grid lines) of
                   traditional scatterplots. We also present methods for
                   discovering perturbations on the input data that change the
                   projection the most. The calculation of the perturbations is
                   efficient and easily integrated into programs written in
                   modern programming languages. We present results of
                   DimReader on a variety of NDR methods and datasets both
                   synthetic and real-life, and show how it can be used to
                   compare different NDR methods. Finally, we discuss
                   limitations of our proposal and situations where further
                   research is needed.",
  journal       = "IEEE Trans. Vis. Comput. Graph.",
  month         =  aug,
  year          =  2018,
  url           = "http://dx.doi.org/10.1109/TVCG.2018.2865194",
  language      = "en",
  archivePrefix = "arXiv",
  eprint        = "1710.00992",
  primaryClass  = "cs.HC",
  issn          = "1077-2626, 1941-0506",
  pmid          = "30136997",
  arxivid       = "1710.00992",
  doi           = "10.1109/TVCG.2018.2865194"
}

@ARTICLE{McInnes2018-co,
  title         = "{UMAP}: Uniform Manifold Approximation and Projection for
                   Dimension Reduction",
  author        = "McInnes, Leland and Healy, John and Melville, James",
  abstract      = "UMAP (Uniform Manifold Approximation and Projection) is a
                   novel manifold learning technique for dimension reduction.
                   UMAP is constructed from a theoretical framework based in
                   Riemannian geometry and algebraic topology. The result is a
                   practical scalable algorithm that applies to real world
                   data. The UMAP algorithm is competitive with t-SNE for
                   visualization quality, and arguably preserves more of the
                   global structure with superior run time performance.
                   Furthermore, UMAP has no computational restrictions on
                   embedding dimension, making it viable as a general purpose
                   dimension reduction technique for machine learning.",
  month         =  feb,
  year          =  2018,
  url           = "http://arxiv.org/abs/1802.03426",
  archivePrefix = "arXiv",
  eprint        = "1802.03426",
  primaryClass  = "stat.ML",
  arxivid       = "1802.03426"
}

@ARTICLE{Furnas1994-qf,
  title     = "Prosection Views: Dimensional Inference through Sections and
               Projections",
  author    = "Furnas, George W and Buja, Andreas",
  abstract  = "Abstract We present some basic properties of two general
               graphical techniques for constructing views of high-dimensional
               objects, projection and section. Projections can easily display
               aspects of structure that are only of low dimension, and
               sections?that is, intersections of subspaces with a
               high-dimensional object?can easily display structure of only low
               codimension (and hence often high dimension). However,
               compositions of sections and projections, here called
               prosections, can display aspects of structure of any
               intermediate dimension. These statements are relevant for data
               analysis: projections of data can be easily generated with x-y
               scatterplots, three-dimensional (3-D) data rotations, and grand
               tours; sections can be approximated in existing systems by
               scatterplot brushing and painting. Thus this article is in part
               an investigation into the principles underlying these
               techniques.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.,
               Institute of Mathematical Statistics, Interface Foundation of
               America]",
  volume    =  3,
  number    =  4,
  pages     = "323--353",
  series    = "Ph.D. thesis",
  month     =  dec,
  year      =  1994,
  url       = "http://www.tandfonline.com/doi/abs/10.1080/10618600.1994.10474649",
  issn      = "1061-8600, 1537-2715",
  doi       = "10.1080/10618600.1994.10474649"
}

@ARTICLE{Cook1995-bi,
  title     = "Grand Tour and Projection Pursuit",
  author    = "Cook, Dianne and Buja, Andreas and Cabrera, Javier and Hurley,
               Catherine",
  abstract  = "Abstract The grand tour and projection pursuit are two methods
               for exploring multivariate data. We show how to combine them
               into a dynamic graphical tool for exploratory data analysis,
               called a projection pursuit guided tour. This tool assists in
               clustering data when clusters are oddly shaped and in finding
               general low-dimensional structure in high-dimensional, and in
               particular, sparse data. An example shows that the method, which
               is projection-based, can be quite powerful in situations that
               may cause grief for methods based on kernel smoothing. The
               projection pursuit guided tour is also useful for comparing and
               developing projection pursuit indexes and illustrating some
               types of asymptotic results.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  4,
  number    =  3,
  pages     = "155--172",
  month     =  sep,
  year      =  1995,
  url       = "https://www.tandfonline.com/doi/abs/10.1080/10618600.1995.10474674",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.1995.10474674"
}

@INPROCEEDINGS{Dang2014-mr,
  title     = "{ScagExplorer}: Exploring Scatterplots by Their Scagnostics",
  booktitle = "2014 {IEEE} Pacific Visualization Symposium",
  author    = "Dang, T N and Wilkinson, L",
  abstract  = "A scatter plot displays a relation between a pair of variables.
               Given a set of v variables, there are v(v- 1)/2 pairs of
               variables, and thus the same number of possible pair wise
               scatter plots. Therefore for even small sets of variables, the
               number of scatter plots can be large. Scatter plot matrices
               (SPLOMs) can easily run out of pixels when presenting
               high-dimensional data. We introduce a theoretical method and a
               testbed for assessing whether our method can be used to guide
               interactive exploration of high-dimensional data. The method is
               based on nine characterizations of the 2D distributions of
               orthogonal pair wise projections on a set of points in
               multidimensional Euclidean space. Working directly with these
               characterizations, we can locate anomalies for further analysis
               or search for similar distributions in a large SPLOM with more
               than a hundred dimensions. Our testbed, ScagExplorer, is
               developed in order to evaluate the feasibility of handling huge
               collections of scatter plots.",
  pages     = "73--80",
  month     =  mar,
  year      =  2014,
  url       = "http://dx.doi.org/10.1109/PacificVis.2014.42",
  keywords  = "computer graphics;data handling;graph theory;interactive
               systems;2D distributions;ScagExplorer;high-dimensional
               data;interactive exploration;large SPLOM;multidimensional
               Euclidean space;orthogonal pairwise projections;pairwise
               scatterplots;scatterplot matrices;theoretical
               method;variables;Clustering algorithms;Correlation;Data
               visualization;Educational institutions;Layout;Silicon;Time
               series analysis;Design MethodologyPattern
               analysis;High-Dimensional Visual Analytics;Leader
               algorithm;Scagnostics;Scatterplot matrix;forced-directed layout",
  issn      = "2165-8773",
  doi       = "10.1109/PacificVis.2014.42"
}

@INPROCEEDINGS{Anand2012-tr,
  title     = "Visual Pattern Discovery Using Random Projections",
  booktitle = "Proceedings of the 2012 {IEEE} Conference on Visual Analytics
               Science and Technology ({VAST})",
  author    = "Anand, Anushka and Dang, Tuan Nhon and Wilkinson, Leland",
  publisher = "IEEE Computer Society",
  pages     = "43--52",
  series    = "VAST '12",
  year      =  2012,
  url       = "http://dx.doi.org/10.1109/VAST.2012.6400490",
  address   = "Washington, DC, USA",
  keywords  = "Vectors,Data visualization,Data mining,Manifolds,Indexes,Visual
               analytics,High-dimensional Data,Random Projections",
  isbn      = "9781467347525",
  doi       = "10.1109/VAST.2012.6400490"
}

@ARTICLE{Chen2009-tz,
  title     = "Local Multidimensional Scaling for Nonlinear Dimension
               Reduction, Graph Drawing, and Proximity Analysis",
  author    = "Chen, Lisha and Buja, Andreas",
  abstract  = "In the past decade there has been a resurgence of interest in
               nonlinear dimension reduction. Among new proposals are ?Local
               Linear Embedding,? ?Isomap,? and Kernel Principal Components
               Analysis which all construct global low-dimensional embeddings
               from local affine or metric information. We introduce a
               competing method called ?Local Multidimensional Scaling? (LMDS).
               Like LLE, Isomap, and KPCA, LMDS constructs its global embedding
               from local information, but it uses instead a combination of MDS
               and ?force-directed? graph drawing. We apply the force paradigm
               to create localized versions of MDS stress functions with a
               tuning parameter to adjust the strength of nonlocal repulsive
               forces. We solve the problem of tuning parameter selection with
               a meta-criterion that measures how well the sets of K-nearest
               neighbors agree between the data and the embedding. Tuned LMDS
               seems to be able to outperform MDS, PCA, LLE, Isomap, and KPCA,
               as illustrated with two well-known image datasets. The
               meta-criterion can also be used in a pointwise version as a
               diagnostic tool for measuring the local adequacy of embeddings
               and thereby detect local problems in dimension reductions.",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  104,
  number    =  485,
  pages     = "209--219",
  month     =  mar,
  year      =  2009,
  url       = "https://doi.org/10.1198/jasa.2009.0111",
  issn      = "0162-1459",
  doi       = "10.1198/jasa.2009.0111"
}

@ARTICLE{Buja1996-fk,
  title     = "Interactive {High-Dimensional} Data Visualization",
  author    = "Buja, Andreas and Cook, Dianne and Swayne, Deborah F",
  abstract  = "[We propose a rudimentary taxonomy of interactive data
               visualization based on a triad of data analytic tasks: finding
               Gestalt, posing queries, and making comparisons. These tasks are
               supported by three classes of interactive view manipulations:
               focusing, linking, and arranging views. This discussion extends
               earlier work on the principles of focusing and linking and sets
               them on a firmer base. Next, we give a high-level introduction
               to a particular system for multivariate data
               visualization--XGobi. This introduction is not comprehensive but
               emphasizes XGobi tools that are examples of focusing, linking,
               and arranging views; namely, high-dimensional projections,
               linked scatterplot brushing, and matrices of conditional plots.
               Finally, in a series of case studies in data visualization, we
               show the powers and limitations of particular focusing, linking,
               and arranging tools. The discussion is dominated by
               high-dimensional projections that form an extremely
               well-developed part of XGobi. Of particular interest are the
               illustration of asymptotic normality of high-dimensional
               projections (a theorem of Diaconis and Freedman), the use of
               high-dimensional cubes for visualizing factorial experiments,
               and a method for interactively generating matrices of
               conditional plots with high-dimensional projections. Although
               there is a unifying theme to this article, each section--in
               particular the case studies--can be read separately.]",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "[American Statistical Association, Taylor \& Francis, Ltd.,
               Institute of Mathematical Statistics, Interface Foundation of
               America]",
  volume    =  5,
  number    =  1,
  pages     = "78--99",
  year      =  1996,
  url       = "http://www.jstor.org/stable/1390754",
  issn      = "1061-8600",
  doi       = "10.2307/1390754"
}

@ARTICLE{Sedlmair2013-va,
  title    = "Empirical guidance on scatterplot and dimension reduction
              technique choices",
  author   = "Sedlmair, Michael and Munzner, Tamara and Tory, Melanie",
  abstract = "To verify cluster separation in high-dimensional data, analysts
              often reduce the data with a dimension reduction (DR) technique,
              and then visualize it with 2D Scatterplots, interactive 3D
              Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of
              providing guidance between these visual encoding choices, we
              conducted an empirical data study in which two human coders
              manually inspected a broad set of 816 scatterplots derived from
              75 datasets, 4 DR techniques, and the 3 previously mentioned
              scatterplot techniques. Each coder scored all color-coded classes
              in each scatterplot in terms of their separability from other
              classes. We analyze the resulting quantitative data with a
              heatmap approach, and qualitatively discuss interesting
              scatterplot examples. Our findings reveal that 2D scatterplots
              are often 'good enough', that is, neither SPLOM nor interactive
              3D adds notably more cluster separability with the chosen DR
              technique. If 2D is not good enough, the most promising approach
              is to use an alternative DR technique in 2D. Beyond that, SPLOM
              occasionally adds additional value, and interactive 3D rarely
              helps but often hurts in terms of poorer class separation and
              usability. We summarize these results as a workflow model and
              implications for design. Our results offer guidance to analysts
              during the DR exploration process.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  19,
  number   =  12,
  pages    = "2634--2643",
  month    =  dec,
  year     =  2013,
  url      = "http://dx.doi.org/10.1109/TVCG.2013.153",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "24051830",
  doi      = "10.1109/TVCG.2013.153"
}

@ARTICLE{Ingram2015-vv,
  title    = "Dimensionality reduction for documents with nearest neighbor
              queries",
  author   = "Ingram, Stephen and Munzner, Tamara",
  abstract = "Document collections are often stored as sets of sparse,
              high-dimensional feature vectors. Performing dimensionality
              reduction (DR) on such high-dimensional datasets for the purposes
              of visualization presents algorithmic and qualitative challenges
              for existing DR techniques. We propose the Q-SNE algorithm for
              dimensionality reduction of document data, combining the scalable
              probability-based layout approach of BH-SNE with an improved
              component to calculate approximate nearest neighbors, using the
              query-based APQ approach that exploits an impact-ordered inverted
              file. We provide thorough experimental evidence that Q-SNE yields
              substantial quality improvements for layouts of large document
              collections with commensurate speed. Our experiments were
              conducted with six real-world benchmark datasets that range up to
              millions of documents and terms, and compare against three
              alternatives for nearest neighbor search and five alternatives
              for dimensionality reduction.",
  journal  = "Neurocomputing",
  volume   =  150,
  pages    = "557--569",
  month    =  feb,
  year     =  2015,
  url      = "http://www.sciencedirect.com/science/article/pii/S0925231214012910",
  keywords = "Dimensionality reduction; Document visualization",
  issn     = "0925-2312",
  doi      = "10.1016/j.neucom.2014.07.073"
}

@ARTICLE{Buja2008-fn,
  title     = "Data Visualization With Multidimensional Scaling",
  author    = "Buja, Andreas and Swayne, Deborah F and Littman, Michael L and
               Dean, Nathaniel and Hofmann, Heike and Chen, Lisha",
  abstract  = "We discuss methodology for multidimensional scaling (MDS) and
               its implementation in two software systems, GGvis and XGvis. MDS
               is a visualization technique for proximity data, that is, data
               in the form of N ? N dissimilarity matrices. MDS constructs maps
               (?configurations,? ?embeddings?) in IRk by interpreting the
               dissimilarities as distances. Two frequent sources of
               dissimilarities are high-dimensional data and graphs. When the
               dissimilarities are distances between high-dimensional objects,
               MDS acts as a (often nonlinear) dimension-reduction technique.
               When the dissimilarities are shortest-path distances in a graph,
               MDS acts as a graph layout technique. MDS has found recent
               attention in machine learning motivated by image databases
               (?Isomap?). MDS is also of interest in view of the popularity of
               ?kernelizing? approaches inspired by Support Vector Machines
               (SVMs; ?kernel PCA?).This article discusses the following
               general topics: (1) the stability and multiplicity of MDS
               solutions; (2) the analysis of structure within and between
               subsets of objects with missing value schemes in dissimilarity
               matrices; (3) gradient descent for optimizing general MDS loss
               functions (?Strain? and ?Stress?); (4) a unification of
               classical (Strain-based) and distance (Stress-based)
               MDS.Particular topics include the following: (1) blending of
               automatic optimization with interactive displacement of
               configuration points to assist in the search for global optima;
               (2) forming groups of objects with interactive brushing to
               create patterned missing values in MDS loss functions; (3)
               optimizing MDS loss functions for large numbers of objects
               relative to a small set of anchor points (?external unfolding?);
               and (4) a non-metric version of classical MDS.We show
               applications to the mapping of computer usage data, to the
               dimension reduction of marketing segmentation data, to the
               layout of mathematical graphs and social networks, and finally
               to the spatial reconstruction of molecules.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  17,
  number    =  2,
  pages     = "444--472",
  month     =  jun,
  year      =  2008,
  url       = "https://doi.org/10.1198/106186008X318440",
  eprint    = "http://dx.doi.org/10.1198/106186008X318440",
  issn      = "1061-8600",
  doi       = "10.1198/106186008X318440"
}

@ARTICLE{Satyanarayan2017-gs,
  title    = "{Vega-Lite}: A Grammar of Interactive Graphics",
  author   = "Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat,
              Kanit and Heer, Jeffrey",
  abstract = "We present Vega-Lite, a high-level grammar that enables rapid
              specification of interactive data visualizations. Vega-Lite
              combines a traditional grammar of graphics, providing visual
              encoding rules and a composition algebra for layered and
              multi-view displays, with a novel grammar of interaction. Users
              specify interactive semantics by composing selections. In
              Vega-Lite, a selection is an abstraction that defines input event
              processing, points of interest, and a predicate function for
              inclusion testing. Selections parameterize visual encodings by
              serving as input data, defining scale extents, or by driving
              conditional logic. The Vega-Lite compiler automatically
              synthesizes requisite data flow and event handling logic, which
              users can override for further customization. In contrast to
              existing reactive specifications, Vega-Lite selections decompose
              an interaction design into concise, enumerable semantic units. We
              evaluate Vega-Lite through a range of examples, demonstrating
              succinct specification of both customized interaction methods and
              common techniques such as panning, zooming, and linked selection.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  23,
  number   =  1,
  pages    = "341--350",
  month    =  jan,
  year     =  2017,
  url      = "http://dx.doi.org/10.1109/TVCG.2016.2599030",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "27875150",
  doi      = "10.1109/TVCG.2016.2599030"
}

@ARTICLE{Wattenberg2016-ji,
  title   = "How to Use {t-SNE} Effectively",
  author  = "Wattenberg, Martin and Vi{\'e}gas, Fernanda and Johnson, Ian",
  journal = "Distill",
  volume  =  1,
  number  =  10,
  month   =  oct,
  year    =  2016,
  url     = "http://distill.pub/2016/misread-tsne",
  doi     = "10.23915/distill.00002"
}

@INCOLLECTION{Cook2008-eo,
  title     = "Grand Tours, Projection Pursuit Guided Tours, and Manual
               Controls",
  booktitle = "Handbook of Data Visualization",
  author    = "Cook, Dianne and Buja, Andreas and Lee, Eun-Kyung and Wickham,
               Hadley",
  editor    = "Chen, Chun-Houh and H{\"a}rdle, Wolfgang and Unwin, Antony",
  abstract  = "How do we find structure in multidimensional data when computer
               screens are only two-dimensional? One approach is to project the
               data onto one or two dimensions. Projections are used in
               classical statistical methods like principal component analysis
               (PCA) and linear discriminant analysis. PCA (e.g., Johnson and
               Wichern 2002) chooses a projection to maximize the variance.
               Fisher's linear discriminant (e.g., Johnson and Wichern 2002)
               chooses a projection that maximizes the relative separation
               between group means. Projection pursuit (PP) (e.g., Huber 1985)
               generalizes these ideas into a common strategy, where an
               arbitrary function on projections is optimized. The scatterplot
               matrix (e.g., Becker and Cleveland 1987) also can be considered
               to be a projection method. It shows projections of the data onto
               all pairs of coordinate axes, the 2-D marginal projections of
               the data. These projection methods choose a few select
               projections out of infinitely many.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "295--314",
  series    = "Springer Handbooks Comp.Statistics",
  year      =  2008,
  url       = "https://doi.org/10.1007/978-3-540-33037-0_13",
  address   = "Berlin, Heidelberg",
  language  = "en",
  isbn      = "9783540330370, 9783540330370",
  doi       = "10.1007/978-3-540-33037-0\_13"
}

@ARTICLE{Maaten2008-sk,
  title    = "Visualizing Data using {t-SNE}",
  author   = "Maaten, Laurens van der and Hinton, Geoffrey",
  journal  = "J. Mach. Learn. Res.",
  volume   =  9,
  number   = "Nov",
  pages    = "2579--2605",
  year     =  2008,
  url      = "http://www.jmlr.org/papers/v9/vandermaaten08a.html",
  issn     = "1532-4435, 1533-7928"
}

@ARTICLE{Diaconis2008-fy,
  title         = "Horseshoes in multidimensional scaling and local kernel
                   methods",
  author        = "Diaconis, Persi and Goel, Sharad and Holmes, Susan",
  abstract      = "Classical multidimensional scaling (MDS) is a method for
                   visualizing high-dimensional point clouds by mapping to
                   low-dimensional Euclidean space. This mapping is defined in
                   terms of eigenfunctions of a matrix of interpoint
                   dissimilarities. In this paper we analyze in detail
                   multidimensional scaling applied to a specific dataset: the
                   2005 United States House of Representatives roll call votes.
                   Certain MDS and kernel projections output ``horseshoes''
                   that are characteristic of dimensionality reduction
                   techniques. We show that, in general, a latent ordering of
                   the data gives rise to these patterns when one only has
                   local information. That is, when only the interpoint
                   distances for nearby points are known accurately. Our
                   results provide a rigorous set of results and insight into
                   manifold learning in the special case where the manifold is
                   a curve.",
  month         =  nov,
  year          =  2008,
  url           = "http://arxiv.org/abs/0811.1477",
  archivePrefix = "arXiv",
  eprint        = "0811.1477",
  primaryClass  = "stat.AP",
  arxivid       = "0811.1477",
  doi           = "10.1214/08-AOAS165"
}

@INCOLLECTION{Buja1988-ec,
  title     = "Elements of a viewing pipeline for data analysis",
  booktitle = "Dynamic Graphics for Statistics",
  author    = "Buja, Andreas and Asimov, Daniel and Hurley, Catherine and
               McDonald, John A",
  editor    = "Cleveland, William S and McGill, Marylyn E",
  publisher = "Wadsworth \& Brooks/Cole",
  series    = "Statistics/Probability",
  year      =  1988,
  url       = "https://books.google.com.au/books?hl=en&lr=&id=pZTIv3uq1KsC&oi=fnd&pg=PA277&dq=elements+of+a+data+pipeline&ots=4cuJM6NpDN&sig=ugfwt2lDvTN7-hGlrCdQKCtsx5w"
}

@ARTICLE{Roy_Chowdhury2015-ky,
  title     = "Using visual statistical inference to better understand random
               class separations in high dimension, low sample size data",
  author    = "Roy Chowdhury, Niladri and Cook, Dianne and Hofmann, Heike and
               Majumder, Mahbubul and Lee, Eun-Kyung and Toth, Amy L",
  abstract  = "Statistical graphics play an important role in exploratory data
               analysis, model checking and diagnosis. With high dimensional
               data, this often means plotting low-dimensional projections, for
               example, in classification tasks projection pursuit is used to
               find low-dimensional projections that reveal differences between
               labelled groups. In many contemporary data sets the number of
               observations is relatively small compared to the number of
               variables, which is known as a high dimension low sample size
               (HDLSS) problem. This paper explores the use of visual inference
               on understanding low-dimensional pictures of HDLSS data. Visual
               inference helps to quantify the significance of findings made
               from graphics. This approach may be helpful to broaden the
               understanding of issues related to HDLSS data in the data
               analysis community. Methods are illustrated using data from a
               published paper, which erroneously found real separation in
               microarray data, and with a simulation study conducted using
               Amazon's Mechanical Turk.",
  journal   = "Comput. Stat.",
  publisher = "Springer Berlin Heidelberg",
  volume    =  30,
  number    =  2,
  pages     = "293--316",
  month     =  jun,
  year      =  2015,
  url       = "https://doi.org/10.1007/s00180-014-0534-x",
  language  = "en",
  issn      = "0943-4062",
  doi       = "10.1007/s00180-014-0534-x"
}

@BOOK{Wickham2016-gz,
  title     = "ggplot2: Elegant Graphics for Data Analysis",
  author    = "Wickham, Hadley",
  abstract  = "This new edition to the classic book by ggplot2 creator Hadley
               Wickham highlights compatibility with knitr and RStudio. ggplot2
               is a data visualization package for R that helps users create
               data graphics, including those that are multi-layered, with
               ease. With ggplot2, it's easy to: produce handsome,
               publication-quality plots with automatic legends created from
               the plot specificationsuperimpose multiple layers (points,
               lines, maps, tiles, box plots) from different data sources with
               automatically adjusted common scalesadd customizable smoothers
               that use powerful modeling capabilities of R, such as loess,
               linear models, generalized additive models, and robust
               regressionsave any ggplot2 plot (or part thereof) for later
               modification or reusecreate custom themes that capture in-house
               or journal style requirements and that can easily be applied to
               multiple plotsapproach a graph from a visual perspective,
               thinking about how each component of the data is represented on
               the final plot This book will be useful to everyone who has
               struggled with displaying data in an informative and attractive
               way. Some basic knowledge of R is necessary (e.g., importing
               data into R). ggplot2 is a mini-language specifically tailored
               for producing graphics, and you'll learn everything you need in
               the book. After reading this book you'll be able to produce
               graphics customized precisely for your problems, and you'll find
               it easy to get graphics out of your head and on to the screen or
               page.",
  publisher = "Springer International Publishing",
  series    = "Use R!",
  month     =  jun,
  year      =  2016,
  url       = "https://play.google.com/store/books/details?id=RTMFswEACAAJ",
  language  = "en",
  isbn      = "9783319242750, 9783319242774",
  doi       = "10.1007/978-3-319-24277-4"
}

@BOOK{Cook2007-ld,
  title     = "Interactive and Dynamic Graphics for Data Analysis: With {R} and
               {GGobi}",
  author    = "Cook, Dianne and Swayne, Deborah F and Buja, A",
  publisher = "Springer Science \& Business Media",
  series    = "Use R!",
  month     =  dec,
  year      =  2007,
  url       = "https://play.google.com/store/books/details?id=34DL7lR_4CoC",
  language  = "en",
  isbn      = "9780387717616, 9780387717623",
  doi       = "10.1007/978-0-387-71762-3"
}



@ARTICLE{Sedlmair2013-pn,
  title    = "Empirical guidance on scatterplot and dimension reduction
              technique choices",
  author   = "Sedlmair, Michael and Munzner, Tamara and Tory, Melanie",
  abstract = "To verify cluster separation in high-dimensional data, analysts
              often reduce the data with a dimension reduction (DR) technique,
              and then visualize it with 2D Scatterplots, interactive 3D
              Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of
              providing guidance between these visual encoding choices, we
              conducted an empirical data study in which two human coders
              manually inspected a broad set of 816 scatterplots derived from
              75 datasets, 4 DR techniques, and the 3 previously mentioned
              scatterplot techniques. Each coder scored all color-coded classes
              in each scatterplot in terms of their separability from other
              classes. We analyze the resulting quantitative data with a
              heatmap approach, and qualitatively discuss interesting
              scatterplot examples. Our findings reveal that 2D scatterplots
              are often 'good enough', that is, neither SPLOM nor interactive
              3D adds notably more cluster separability with the chosen DR
              technique. If 2D is not good enough, the most promising approach
              is to use an alternative DR technique in 2D. Beyond that, SPLOM
              occasionally adds additional value, and interactive 3D rarely
              helps but often hurts in terms of poorer class separation and
              usability. We summarize these results as a workflow model and
              implications for design. Our results offer guidance to analysts
              during the DR exploration process.",
  journal  = "IEEE Trans. Vis. Comput. Graph.",
  volume   =  19,
  number   =  12,
  pages    = "2634--2643",
  month    =  dec,
  year     =  2013,
  url      = "http://dx.doi.org/10.1109/TVCG.2013.153",
  language = "en",
  issn     = "1077-2626, 1941-0506",
  pmid     = "24051830",
  doi      = "10.1109/TVCG.2013.153"
}

@ARTICLE{Buja1996-rp,
  title     = "Interactive {High-Dimensional} Data Visualization",
  author    = "Buja, Andreas and Cook, Dianne and Swayne, Deborah F",
  abstract  = "Abstract We propose a rudimentary taxonomy of interactive data
               visualization based on a triad of data analytic tasks: finding
               Gestalt, posing queries, and making comparisons. These tasks are
               supported by three classes of interactive view manipulations:
               focusing, linking, and arranging views. This discussion extends
               earlier work on the principles of focusing and linking and sets
               them on a firmer base. Next, we give a high-level introduction
               to a particular system for multivariate data
               visualization?XGobi. This introduction is not comprehensive but
               emphasizes XGobi tools that are examples of focusing, linking,
               and arranging views; namely, high-dimensional projections,
               linked scatterplot brushing, and matrices of conditional plots.
               Finally, in a series of case studies in data visualization, we
               show the powers and limitations of particular focusing, linking,
               and arranging tools. The discussion is dominated by
               high-dimensional projections that form an extremely
               well-developed part of XGobi. Of particular interest are the
               illustration of asymptotic normality of high-dimensional
               projections (a theorem of Diaconis and Freedman), the use of
               high-dimensional cubes for visualizing factorial experiments,
               and a method for interactively generating matrices of
               conditional plots with high-dimensional projections. Although
               there is a unifying theme to this article, each section?in
               particular the case studies?can be read separately.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  5,
  number    =  1,
  pages     = "78--99",
  month     =  mar,
  year      =  1996,
  url       = "https://www.tandfonline.com/doi/abs/10.1080/10618600.1996.10474696",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.1996.10474696"
}

@ARTICLE{Unwin2018-zb,
  title     = "Ensemble Graphics",
  author    = "Unwin, Antony and Valero-Mora, Pedro",
  abstract  = "ABSTRACTOne graphic can convey a lot of information and several
               graphics linked together in a coherent ensemble can convey even
               more. This article describes the principles underlying ensemble
               graphics, their key dimensions, and where they are of most use.
               Ensemble graphics must have strong common themes and carefully
               constructed layouts. Appropriate interactive tools are
               important. Ensembles can be used flexibly for EDA or in a more
               structured fashion for supporting modeling and for
               presentations.",
  journal   = "J. Comput. Graph. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  27,
  number    =  1,
  pages     = "157--165",
  month     =  jan,
  year      =  2018,
  url       = "https://doi.org/10.1080/10618600.2017.1383264",
  issn      = "1061-8600",
  doi       = "10.1080/10618600.2017.1383264"
}


@ARTICLE{Wickham2015-cx,
  title     = "Visualizing statistical models: Removing the blindfold",
  author    = "Wickham, Hadley and Cook, Dianne and Hofmann, Heike",
  abstract  = "Visualization can help in model building, diagnosis, and in
               developing an understanding about how a model summarizes data.
               This paper proposes three strategies for visualizing statistical
               models: (i) display the model in the data space, (ii) look at
               all members of a collection, and (iii) explore the process of
               model fitting, not just the end result. Each strategy is
               accompanied by examples, including manova, classification
               algorithms, hierarchical clustering, ensembles of linear models,
               projection pursuit, self-organizing maps, and neural networks.",
  journal   = "Statistical Analysis and Data Mining: The ASA Data Science
               Journal",
  publisher = "Wiley Subscription Services, Inc., A Wiley Company",
  volume    =  8,
  number    =  4,
  pages     = "203--225",
  month     =  aug,
  year      =  2015,
  url       = "http://dx.doi.org/10.1002/sam.11271",
  keywords  = "model visualization; exploratory data analysis; data mining;
               classification; high-dimensional data",
  issn      = "1932-1872",
  doi       = "10.1002/sam.11271"
}


@ARTICLE{Smilkov2016-hp,
  title         = "Embedding Projector: Interactive Visualization and
                   Interpretation of Embeddings",
  author        = "Smilkov, Daniel and Thorat, Nikhil and Nicholson, Charles
                   and Reif, Emily and Vi{\'e}gas, Fernanda B and Wattenberg,
                   Martin",
  abstract      = "Embeddings are ubiquitous in machine learning, appearing in
                   recommender systems, NLP, and many other applications.
                   Researchers and developers often need to explore the
                   properties of a specific embedding, and one way to analyze
                   embeddings is to visualize them. We present the Embedding
                   Projector, a tool for interactive visualization and
                   interpretation of embeddings.",
  month         =  nov,
  year          =  2016,
  url           = "http://arxiv.org/abs/1611.05469",
  archivePrefix = "arXiv",
  eprint        = "1611.05469",
  primaryClass  = "stat.ML",
  arxivid       = "1611.05469"
}

  @Manual{baseR,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2019},
    url = {https://www.R-project.org/},
  }


% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cavallo2018-aj,
  title     = "A visual interaction framework for dimensionality reduction
               based data exploration",
  author    = "Cavallo, M and Demiralp, {\c C}",
  abstract  = "Dimensionality reduction is a common method for analyzing and
               visualizing high- dimensional data. However, reasoning
               dynamically about the results of a dimensionality reduction is
               difficult. Dimensionality-reduction algorithms use complex
               optimizations to …",
  journal   = "Proceedings of the 2018 CHI Conference on",
  publisher = "dl.acm.org",
  year      =  2018,
  url       = "https://dl.acm.org/doi/abs/10.1145/3173574.3174209"
}

@ARTICLE{Tang2016-oz,
  title         = "Visualizing Large-scale and High-dimensional Data",
  author        = "Tang, Jian and Liu, Jingzhou and Zhang, Ming and Mei,
                   Qiaozhu",
  abstract      = "We study the problem of visualizing large-scale and
                   high-dimensional data in a low-dimensional (typically 2D or
                   3D) space. Much success has been reported recently by
                   techniques that first compute a similarity structure of the
                   data points and then project them into a low-dimensional
                   space with the structure preserved. These two steps suffer
                   from considerable computational costs, preventing the
                   state-of-the-art methods such as the t-SNE from scaling to
                   large-scale and high-dimensional data (e.g., millions of
                   data points and hundreds of dimensions). We propose the
                   LargeVis, a technique that first constructs an accurately
                   approximated K-nearest neighbor graph from the data and then
                   layouts the graph in the low-dimensional space. Comparing to
                   t-SNE, LargeVis significantly reduces the computational cost
                   of the graph construction step and employs a principled
                   probabilistic model for the visualization step, the
                   objective of which can be effectively optimized through
                   asynchronous stochastic gradient descent with a linear time
                   complexity. The whole procedure thus easily scales to
                   millions of high-dimensional data points. Experimental
                   results on real-world data sets demonstrate that the
                   LargeVis outperforms the state-of-the-art methods in both
                   efficiency and effectiveness. The hyper-parameters of
                   LargeVis are also much more stable over different data sets.",
  month         =  feb,
  year          =  2016,
  url           = "http://arxiv.org/abs/1602.00370",
  archivePrefix = "arXiv",
  eprint        = "1602.00370",
  primaryClass  = "cs.LG",
  arxivid       = "1602.00370"
}
